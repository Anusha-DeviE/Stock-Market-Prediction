# -*- coding: utf-8 -*-
"""Stock Market Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UrSkk7UOx8RjPNnN5QmH6E3r4xKHyZo0
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import yfinance as yf
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout
from keras.callbacks import EarlyStopping, ReduceLROnPlateau

# Step 1: Load Data
ticker = 'AAPL'
df = yf.download(ticker, start='2015-01-01', end='2023-12-31')
plt.figure(figsize=(12,6))
plt.plot(df['Close'])
plt.title(f'{ticker} Closing Prices')
plt.xlabel('Date')
plt.ylabel('Price')
plt.show()

# Step 2: Preprocessing (Using OHLCV)
data = df[['Open', 'High', 'Low', 'Close', 'Volume']].values
scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data)

train_len = int(len(data_scaled) * 0.8)
train_data = data_scaled[:train_len]
test_data = data_scaled[train_len:]

def create_sequences(data, seq_len):
    X, y = [], []
    for i in range(seq_len, len(data)):
        X.append(data[i-seq_len:i])
        y.append(data[i, 3])  # index 3 = 'Close' after scaling
    return np.array(X), np.array(y)

seq_len = 60
X_train, y_train = create_sequences(train_data, seq_len)
X_test, y_test = create_sequences(test_data, seq_len)

# Step 3: Model Architecture (CNN + Stacked LSTM + Dropout)
model = Sequential()
model.add(Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(MaxPooling1D(pool_size=2))
model.add(LSTM(units=100, return_sequences=True))
model.add(LSTM(units=50))
model.add(Dropout(0.3))
model.add(Dense(1))

model.compile(loss='huber', optimizer='adam', metrics=['mae'])

# Callbacks
early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5, min_lr=1e-6)

# Step 4: Model Training
history = model.fit(
    X_train, y_train,
    validation_split=0.1,
    epochs=30,
    batch_size=64,
    callbacks=[early_stop, reduce_lr],
    verbose=1
)

# Step 5: Save Model
model.save("cnn_lstm_model.h5")

# Step 6: Prediction
predicted = model.predict(X_test)
predicted = scaler.inverse_transform(np.concatenate([
    np.zeros((predicted.shape[0], 3)),     # dummy for Open, High, Low
    predicted,                             # predicted Close
    np.zeros((predicted.shape[0], 1))      # dummy for Volume
], axis=1))[:, 3]  # get only inverse of predicted Close

actual = scaler.inverse_transform(np.concatenate([
    np.zeros((len(y_test), 3)),
    y_test.reshape(-1,1),
    np.zeros((len(y_test), 1))
], axis=1))[:, 3]

# Step 7: Plot Actual vs Predicted
plt.figure(figsize=(12,6))
plt.plot(actual, label='Actual Price')
plt.plot(predicted, label='Predicted Price')
plt.legend()
plt.title('Actual vs Predicted Closing Price (CNN + LSTM Model)')
plt.show()

# Step 8: Plot Loss Graph
plt.figure(figsize=(10, 4))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title("Loss over Epochs")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.show()